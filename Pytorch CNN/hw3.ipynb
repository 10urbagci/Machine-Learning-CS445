{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import scipy.misc\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import pickle\n",
        "import argparse\n"
      ],
      "metadata": {
        "id": "_OZOStVsfywk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/gdrive/MyDrive/Colab Notebooks/hw3/art_data'\n",
        "DATA_FILE = DATA_PATH + 'art_data.pickle'\n",
        "IMAGE_SIZE = 50\n",
        "NUM_CHANNELS = 3\n",
        "NUM_LABELS = 11\n",
        "INCLUDE_TEST_SET = False"
      ],
      "metadata": {
        "id": "rtYelMTzi5Ja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "wKyZGGsg3W98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# Hyperparameters\n",
        "batch_size = 10\n",
        "learning_rate = 0.01\n",
        "num_training_steps = 1501\n",
        "# Enable dropout and weight decay normalization\n",
        "dropout_prob = 0.0 # set to > 0.0 to apply dropout, 0.0 to remove\n",
        "weight_penalty = 0.0 # set to > 0.0 to apply weight penalty, 0.0 to remove\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def _init_(self):\n",
        "        super(CNN, self)._init_()\n",
        "\n",
        "        # Network Architecture Parameters\n",
        "        ############################################################################\n",
        "        layer1_filter_size = 5\n",
        "        layer1_depth = 16\n",
        "        layer1_stride = 2\n",
        "        layer2_filter_size = 5\n",
        "        layer2_depth = 16\n",
        "        layer2_stride = 2\n",
        "        layer3_num_hidden = 64\n",
        "\n",
        "        # Add max pooling\n",
        "        self.pooling = False\n",
        "        layer1_pool_filter_size = 2\n",
        "        layer1_pool_stride = 2\n",
        "        layer2_pool_filter_size = 2\n",
        "        layer2_pool_stride = 2\n",
        "\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        # Define Layers\n",
        "        #########################################################################################################\n",
        "        self.conv1 = nn.Conv2d(NUM_CHANNELS, layer1_depth, kernel_size=layer1_filter_size, stride = layer1_stride, padding=layer1_filter_size//2)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pooling1 = nn.MaxPool2d(kernel_size = layer1_pool_filter_size, stride = layer1_pool_stride)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(layer1_depth, layer2_depth, kernel_size=layer2_filter_size, stride = layer2_stride, padding=layer2_filter_size//2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pooling2 = nn.MaxPool2d(kernel_size = layer2_pool_filter_size, stride = layer2_pool_stride)\n",
        "\n",
        "\n",
        "        feature_size = int(math.ceil(IMAGE_SIZE/(layer1_stride*layer2_stride))) if not self.pooling else \\\n",
        "                            int(math.ceil(IMAGE_SIZE/(layer1_stride*layer2_stride*layer2_pool_stride*layer2_pool_stride)))\n",
        "        self.feature_in = feature_size**2*layer2_depth\n",
        "        self.fc = nn.Linear(self.feature_in,layer3_num_hidden )\n",
        "        self.fc_relu = nn.ReLU()\n",
        "        self.fc_dropout = nn.Dropout(p=dropout_prob)\n",
        "\n",
        "        self.out = nn.Linear(layer3_num_hidden,NUM_LABELS)\n",
        "        #########################################################################################################\n",
        "\n",
        "    # define data propagation through the layers\n",
        "    def forward(self, img):\n",
        "        # reshape input tensor from Batch x Height x Width x Channles(3)\n",
        "        # to Batch x Channles(3)x Height x Width\n",
        "        img =img.permute(0,3,1,2)\n",
        "\n",
        "        self.out1 = self.conv1(img)\n",
        "        self.out1 = self.relu1(self.out1)\n",
        "        if self.pooling:\n",
        "            self.out1 = self.pooling1(self.out1)\n",
        "\n",
        "        self.out2 = self.conv2(self.out1)\n",
        "        self.out2 = self.relu2(self.out2)\n",
        "        if self.pooling:\n",
        "            self.out2 = self.pooling2(self.out2)\n",
        "\n",
        "        # reshape the convolution feature map to a vector of size C*H*W\n",
        "        B,C,H,W = self.out2.shape\n",
        "        self.out2 = self.out2.reshape(B,C*H*W)\n",
        "\n",
        "\n",
        "        self.out3 = self.fc(self.out2)\n",
        "        self.out3 = self.fc_relu(self.out3)\n",
        "        self.out3 = self.fc_dropout(self.out3)\n",
        "\n",
        "        self.out_final = self.out(self.out3)\n",
        "        self.out_final = F.softmax(self.out_final, dim=1)\n",
        "\n",
        "        return self.out_final\n",
        "\n",
        "def get_torch_vars(xs, ys, gpu=False):\n",
        "    xs = torch.from_numpy(xs).float()\n",
        "    ys = torch.from_numpy(ys).long()\n",
        "    if gpu:\n",
        "        xs = xs.cuda()\n",
        "        ys = ys.cuda()\n",
        "    return Variable(xs), Variable(ys)\n",
        "\n",
        "def load_data():\n",
        "    print (\"Loading datasets...\")\n",
        "\n",
        "    with open(DATA_FILE, 'rb') as f:\n",
        "        save = pickle.load(f,encoding='bytes')\n",
        "        train_X = save[b'train_data']\n",
        "        train_Y = save[b'train_labels']\n",
        "        val_X = save[b'val_data']\n",
        "        val_Y = save[b'val_labels']\n",
        "        print ('Training set', train_X.shape, train_Y.shape)\n",
        "        print ('Validation set', val_X.shape, val_Y.shape)\n",
        "\n",
        "        if INCLUDE_TEST_SET:\n",
        "            test_X = save[b'test_data']\n",
        "            test_Y = save[b'test_labels']\n",
        "            print ('Test set', test_X.shape, test_Y.shape)\n",
        "            del save\n",
        "            return (train_X,train_Y),(val_X,val_Y),(test_X,test_Y)\n",
        "\n",
        "\n",
        "        del save  # hint to help gc free up memory\n",
        "\n",
        "    return (train_X,train_Y),(val_X,val_Y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_invariance_datasets():\n",
        "    with open(DATA_PATH + 'invariance_art_data.pickle', 'rb') as f:\n",
        "        save = pickle.load(f,encoding='bytes')\n",
        "        translated_val_X = save[b'translated_val_data']\n",
        "        flipped_val_X = save[b'flipped_val_data']\n",
        "        inverted_val_X = save[b'inverted_val_data']\n",
        "        bright_val_X = save[b'bright_val_data']\n",
        "        dark_val_X = save[b'dark_val_data']\n",
        "        high_contrast_val_X = save[b'high_contrast_val_data']\n",
        "        low_contrast_val_X = save[b'low_contrast_val_data']\n",
        "        del save\n",
        "    return [translated_val_X,flipped_val_X,inverted_val_X,\n",
        "                bright_val_X,dark_val_X,high_contrast_val_X,low_contrast_val_X]\n",
        "\n",
        "def run_validation_step(cnn, criterion, val_x, val_y, batch_size, gpu=False):\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    losses = []\n",
        "    for batch in range(0,len(val_x),batch_size):\n",
        "        images = val_x[batch:batch+batch_size, :,:,:]\n",
        "        labels = val_y[batch:batch+batch_size,:]\n",
        "        images, labels = get_torch_vars(images, labels, gpu)\n",
        "        labels = torch.argmax(labels, dim=1)\n",
        "        preds = model(images)\n",
        "\n",
        "        val_loss = criterion(preds,labels)\n",
        "        losses.append(val_loss.item())\n",
        "\n",
        "        _, predicted = torch.max(preds, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum()\n",
        "\n",
        "    assert total == len(val_y), f'total {total} should be == to {len(val_y)}'\n",
        "    val_loss = np.mean(losses)\n",
        "    val_acc = 100 * correct / total\n",
        "    return val_loss, val_acc\n",
        "\n",
        "def train(model, train_x, train_y,val_x, val_y, criterion, gpu=False ):\n",
        "\n",
        "    print(\"Beginning training ...\")\n",
        "    if gpu: model.cuda()\n",
        "    start = time.time()\n",
        "\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    valid_accs = []\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = weight_penalty)\n",
        "    for step in range(num_training_steps):\n",
        "        # Train the Model\n",
        "        model.train() # Change model to 'train' mode\n",
        "        losses = []\n",
        "        # get a batch of data\n",
        "        offset = (step * batch_size) % (train_y.shape[0] - batch_size)\n",
        "        images = train_x[offset:(offset + batch_size), :, :, :]\n",
        "        labels = train_y[offset:(offset + batch_size), :]\n",
        "        # get tensors to feed to the model\n",
        "        images, labels = get_torch_vars(images, labels, gpu)\n",
        "        labels = torch.argmax(labels, dim=1)\n",
        "        # Forward + Backward + Optimize\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(images)\n",
        "\n",
        "        loss  = criterion(preds,labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        if (step+1)%100 == 0:\n",
        "            # Change model to 'eval' mode\n",
        "            model.eval()\n",
        "\n",
        "            avg_loss = np.mean(losses)\n",
        "            train_losses.append(avg_loss)\n",
        "\n",
        "            # Evaluate the model\n",
        "            val_loss, val_acc = run_validation_step(model,criterion,val_x, val_y,batch_size, gpu)\n",
        "\n",
        "            time_elapsed = time.time() - start\n",
        "            valid_losses.append(val_loss)\n",
        "            valid_accs.append(val_acc)\n",
        "            print(f' Step {step+1}/{num_training_steps}, Loss: {avg_loss:.4f} Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.1f}, Time(s):{time_elapsed:.2f}')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "if __name__ == '_main_':\n",
        "\n",
        "    parser = argparse.ArgumentParser(description=\"Train Artists\")\n",
        "\n",
        "    parser.add_argument('--gpu', action='store_true', default=False,\n",
        "                        help=\"Use GPU for training\")\n",
        "    parser.add_argument('--invariance', action=\"store_true\", default=False,\n",
        "                        help=\"Validate on invariance data\")\n",
        "\n",
        "    \n",
        "    args = parser.parse_args()\n",
        "   \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model = CNN()\n",
        "\n",
        "\n",
        "\n",
        "    (train_X,train_Y),(val_X,val_Y) = load_data()\n",
        "    model = train(model, train_X,train_Y,val_X,val_Y,criterion, gpu=True)\n",
        "    invariance=False\n",
        "    if not invariance:\n",
        "        model.eval()\n",
        "        val_loss, val_acc = run_validation_step(model,criterion,val_X,val_Y,batch_size, True)\n",
        "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.1f}')\n",
        "    else:\n",
        "        invariance_sets = load_invariance_datasets()\n",
        "        sets = [val_X]+invariance_sets\n",
        "        set_names = ['normal validation', 'translated', 'brightened', 'darkened',\n",
        "                     'high contrast', 'low contrast', 'flipped', 'inverted']\n",
        "        for i in range(len(set_names)):\n",
        "            model.eval()\n",
        "            _, val_acc = run_validation_step(model,criterion,sets[i],val_Y,batch_size, True)\n",
        "            print(f'Accuracy on {set_names[i]} Acc: {val_acc:.1f}')"
      ],
      "metadata": {
        "id": "mVjcR0_li7Kk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}